### YamlMime:Course
title: Data Engineering on Microsoft Azure
metadata:
  title: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
  description: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
uid: course.dp-203t00
courseNumber: 'DP-203T00-A'
hoursToComplete: 96
iconUrl: /media/learn/certification/course.svg
skillsGained:
- skill: Explorar opções de computação e armazenamento para cargas de trabalho de engenharia de dados no Azure
- skill: Executar queries interativas usando pools SQL sem servidor
- skill: Executar exploração e transformação de dados em Azure Databricks
- skill: Explorar, transformar e carregar dados no Data Warehouse usando Apache Spark
- skill: Ingerir e carregar Dados no Armazém de Dados
- skill: Transformar dados com a  Azure Data Factory ou Azure Synapse Pipelines
- skill: Integrar dados de Notebooks com a Azure Data Factory ou Azure Synapse Pipeline
- skill: Suportar Processamento Analítico Transacional Híbrido (HTAP) com Azure Synapse Link
- skill: Executar segurança de ponta a ponta com Azure Synapse Analytics
- skill: Realizar processamento de fluxo em tempo real com o Stream Analytics
- skill: Criar uma solução de processamento de fluxo com Event Hubs e habilidade de databricks
learningPartnersLink: /learn/certifications/partners
locales:
- en
levels:
- intermediate
roles:
- data-engineer
products:
- azure
exams:
- uid: exam.dp-203
summary: |-
  Neste curso, o aluno aprenderá sobre a engenharia de dados no que se refere ao trabalho com soluções analíticas em lote e em tempo real usando tecnologias de plataforma de dados Azure. Os alunos começarão por entender as tecnologias básicas de computação e armazenamento usadas para construir uma solução analítica. Os alunos aprenderão como explorar interativamente dados armazenados em arquivos em um data lake. Eles aprenderão as várias técnicas de ingestão que podem ser usadas para carregar dados usando o recurso Apache Spark encontrado no Azure Synapse Analytics ou Azure Databricks ou como fazer a ingestão usando o Azure Data Factory ou os pipelines do Azure Synapse. Os alunos também aprenderão as várias maneiras de transformar os dados usando as mesmas tecnologias usadas para ingerir dados. Eles compreenderão a importância de implementar segurança para garantir que os dados sejam protegidos em repouso ou em trânsito. O aluno então mostrará como criar um sistema analítico em tempo real para criar soluções analíticas em tempo real. 

  #### Perfil de audiência 
  O principal público para este curso são profissionais de dados, arquitetos de dados e profissionais de inteligência de negócios que querem aprender sobre engenharia de dados e construir soluções analíticas usando tecnologias de plataforma de dados que existem no Microsoft Azure. O público secundário para este curso de analistas de dados e cientistas de dados que trabalham com soluções analíticas construídas no Microsoft Azure.
prerequisitesSection: |-
  Os alunos de sucesso iniciam este curso com conhecimento de computação em cloud e conceitos de dados principais e experiência profissional com soluções de dados. 

  Conclusão de especificamente&#58;

  - AZ-900 - Fundamentos Azure
  - DP-900 - Microsoft Azure Data Fundamentals
outlineSection: |-
  ### Módulo 1&#58; Explorar opções de computação e armazenamento para cargas de trabalho de engenharia de dados
  Este módulo fornece uma visão geral das opções de tecnologia de computação e armazenamento do Azure que estão disponíveis para engenheiros de dados construindo cargas de trabalho analíticas. Este módulo ensina maneiras de estruturar o lago de dados e otimizar os arquivos para exploração, streaming e cargas de trabalho em lote. O aluno aprenderá a organizar o lago de dados em níveis de refinamento de dados à medida que transforma arquivos através de processamento em lote e fluxo. Em seguida, eles aprenderão como criar índices em seus conjuntos de dados, como CSV, JSON, e arquivos Parquet, e usá-los para consulta potencial e aceleração de carga de trabalho.
  #### Aulas
  - Introdução a Azure Synapse Analytics 
  - Descrever Azure Databricks
  - Introdução ao armazenamento da Azure Data Lake 
  - Descrever Delta Lake arquitetura
  - Trabalhar com fluxos de dados usando Azure Stream Analytics 

  #### Laboratório &#58; Explorar opções de computação e armazenamento para cargas de trabalho de engenharia de dados
  * Combinar streaming e processamento em lote com um único pipeline
  *   Organizar o data lake em níveis de transformação de arquivo
  *   Índice de armazenamento de data lake para consulta e aceleração de carga de trabalho
  
  Após a conclusão deste módulo, os alunos serão capazes de&#58;
  - Descrever Azure Synapse Analytics 
  - Descrever Azure Databricks
  - Descrever armazenamento de Azure Data Lake
  - Descrever arquitetura Delta Lake 
  - Descrever Azure Stream Analytics 
    
  ### Módulo 2&#58; Execute queries interativas usando Azure Synapse Analytics SQL Pools sem servidor
  Neste módulo, os alunos aprenderão a trabalhar com arquivos armazenados no lago de dados e fontes externas de arquivos, através de  declarações T-SQL executadas por um servidor SQL pool em Azure Synapse Analytics. Os alunos consultarão arquivos do Parquet armazenados num lago de dados, bem como arquivos CSV armazenados numa loja de dados externa. Em seguida, eles irão criar grupos Azure Active Directory de segurança e impor acesso a arquivos no lago de dados através do Controle de Acesso Baseado em Funções (RBAC) e Listas de Controle de Acesso (ACLs).
  #### Aulas
  - Explorar Azure Synapse capacidades de pools SQL sem servidor  
  - Dados de consulta no lago usando pools SQL da Azure Synapse sem servidor
  - Criar objetos de metadados nos Pools SQL da Azure Synapse sem servidor
  - Proteger dados e gerenciar usuários nos Pools SQL da Azure Synapse sem servidor
  
  #### Laboratório &#58; Executar queries interativas usando SQL Pools sem servidor 
  - Consultar dados do Parquet com SQL Pools sem servidor
  - Criar tabelas externas para o Parquet e arquivos CSV
  - Criar visualizações de SQL Pools sem servidor
  - Acesso seguro a dados num lago de dados ao usar SQL Pools sem servidor
  - Configurar a segurança do lago de dados usando o Controle de Acesso Baseado em Função (RBAC) e Lista de Controle de Acesso
  
  Após a conclusão deste módulo, os alunos serão capazes de&#58;
  - Entender Azure Synapse capacidades de pools SQL sem servidor 
  -  Consultar dados no lago usando SQL Pools sem servidor da Azure Synapse 
  - Criar objetos de metadados nos SQL Pools sem servidor da Azure Synapse 
  - Proteger dados e gerenciar usuários nos SQL Pools sem servidor da Azure Synapse 
  
  
  ### Módulo 3: Exploração e transformação de dados no Azure Databricks

  Este módulo ensina como usar vários métodos Apache Spark DataFrame para explorar e transformar dados em Azure Databricks. O aluno aprenderá como executar métodos DataFrame padrão para explorar e transformar dados. Eles também aprenderão como executar tarefas mais avançadas, como remover dados duplicados, manipular valores de data/hora, renomear colunas e agregar dados.

  #### Lições

  *   Descrever Azure Databricks

  *   Ler e gravar dados no Azure Databricks

  *   Trabalhar com DataFrames em Azure Databricks

  *   Trabalhar com métodos avançados de DataFrames em Azure Databricks


  #### Laboratório: Exploração e transformação de dados em Azure Databricks

  ####
  *   Usar DataFrames no Azure Databricks para explorar e filtrar dados
  *   Armazenar um DataFrame para consultas subsequentes mais rápidas
  *   Remover dados duplicados
  *   Manipular valores de data/hora
  *   Remover e renomear colunas DataFrame
  *   Agregar dados armazenados em um DataFrame

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Descrever Azure Databricks

  *   Ler e gravar dados no Azure Databricks

  *   Trabalhar com DataFrames em Azure Databricks

  *   Trabalhar com métodos avançados de DataFrames em Azure Databricks


  ### Módulo 4: Explorar, transformar e carregar dados no Data Warehouse usando Apache Spark

  Este módulo ensina como explorar dados armazenados em um data lake, transformar os dados e carregar dados em um armazenamento de dados relacional. O aluno explorará arquivos Parquet e JSON e usará técnicas para consultar e transformar arquivos JSON com estruturas hierárquicas. Em seguida, o aluno usará o Apache Spark para carregar dados no data warehouse e juntar os dados Parquet no data lake com os dados no pool SQL dedicado.

  #### Lições

  *   Compreender a engenharia de big data com Apache Spark no Azure Synapse Analytics

  *   Ingerir dados com notebooks Apache Spark no Azure Synapse Analytics

  *   Transformar dados com DataFrames em Apache Spark Pools no Azure Synapse Analytics

  *   Integrar pools SQL e Apache Spark no Azure Synapse Analytics


  #### Laboratório: Explorar, transformar e carregar dados no Data Warehouse usando Apache Spark

  ####
  *   Realizar exploração de dados no Synapse Studio
  *   Ingerir dados com blocos de anotações Spark no Azure Synapse Analytics
  *   Transformar dados com DataFrames em pools Spark no Azure Synapse Analytics
  *   Integrar pools SQL e Spark no Azure Synapse Analytics

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Descrever a engenharia de big data com Apache Spark no Azure Synapse Analytics

  *   Ingerir dados com notebooks Apache Spark no Azure Synapse Analytics

  *   Transformar dados com DataFrames em Apache Spark Pools no Azure Synapse Analytics

  *   Integrar pools SQL e Apache Spark no Azure Synapse Analytics
  
  ### Módulo 5: ingerir e carregar dados no data warehouse

  Este módulo ensina os alunos a ingerir dados no data warehouse por meio de scripts T-SQL e pipelines de integração do Synapse Analytics. O aluno aprenderá como carregar dados em pools SQL dedicados do Synapse com PolyBase e COPY usando T-SQL. O aluno também aprenderá como usar o gerenciamento de carga de trabalho junto com uma atividade de cópia em um pipeline do Azure Synapse para ingestão de dados em escala de petabyte.

  #### Lições

  *   Usar as melhores práticas de carregamento de dados no Azure Synapse Analytics

  *   Ingestão em escala de petabyte com Azure Data Factory


  #### Laboratório: ingerir e carregar dados no data warehouse

  ####
  *   Executar a ingestão em escala de petabyte com Azure Synapse Pipelines
  *   Importar dados com PolyBase e COPY usando T-SQL
  *   Usar as melhores práticas de carregamento de dados no Azure Synapse Analytics

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Usar as melhores práticas de carregamento de dados no Azure Synapse Analytics

  *   Ingestão em escala de petabyte com Azure Data Factory


  ### Módulo 6: Transformar dados com Azure Data Factory ou Azure Synapse Pipelines

  Este módulo ensina aos alunos como construir pipelines de integração de dados para ingerir de várias fontes de dados, transformar dados usando fluxos de dados de mapeamento e realizar movimentação de dados em um ou mais coletores de dados.

  #### Lições

  *   Integração de dados com Azure Data Factory ou Azure Synapse Pipelines

  *   Transformação livre de código em escala com Azure Data Factory ou Azure Synapse Pipelines


  #### Laboratório: Transformar dados com Azure Data Factory ou Azure Synapse Pipelines

  ####
  *   Executar transformações sem código em escala com Azure Synapse Pipelines
  *   Criar pipeline de dados para importar arquivos CSV mal formatados
  *   Criar fluxos de dados de mapeamento

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Realizar integração de dados com Azure Data Factory

  *   Executar a transformação livre de código em escala com o Azure Data Factory
  
  ### Módulo 7: orquestrar a movimentação e transformação de dados em Azure Synapse Pipelines

  Neste módulo, você aprenderá como criar serviços vinculados e orquestrar a movimentação e transformação de dados usando blocos de anotações no Azure Synapse Pipelines.

  #### Lições

  *   Orquestrar a movimentação e transformação de dados no Azure Data Factory


  #### Laboratório: orquestrar a movimentação e transformação de dados em Azure Synapse Pipelines

  ####
  *   Integrar dados de notebooks com Azure Data Factory ou Azure Synapse Pipelines

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Orquestrar a movimentação e transformação de dados em Azure Synapse Pipelines


  ### Módulo 8: Segurança ponta a ponta com Azure Synapse Analytics

  Neste módulo, os alunos aprenderão como proteger um espaço de trabalho do Synapse Analytics e sua infraestrutura de suporte. O aluno observará o SQL Active Directory Admin, gerenciará regras de firewall de IP gerenciará segredos com o Azure Key Vault e acessará esses segredos por meio de um serviço vinculado ao Key Vault e atividades de pipeline. O aluno compreenderá como implementar segurança em nível de coluna, segurança em nível de linha e mascaramento de dados dynamic ao usar pools SQL dedicados.

  #### Lições

  *   Proteger um armazém de dados no Azure Synapse Analytics

  *   Configurar e gerenciar segredos no Azure Key Vault

  *   Implementar controles de conformidade para dados confidenciais


  #### Laboratório: Segurança ponta a ponta com Azure Synapse Analytics

  ####
  *   Infraestrutura segura de suporte do Azure Synapse Analytics
  *   Proteger o espaço de trabalho e serviços gerenciados do Azure Synapse Analytics
  *   Proteger os dados do espaço de trabalho do Azure Synapse Analytics

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Proteger um data warehouse no Azure Synapse Analytics

  *   Configurar e gerenciar segredos no Azure Key Vault

  *   Implementar controles de conformidade para dados confidenciais
  
  ### Módulo 9: Suporte ao Hybrid Transactional Analytical Processing (HTAP) com o Azure Synapse Link

  Neste módulo, os alunos aprenderão como o Azure Synapse Link permite a conectividade perfeita de uma conta do Azure Cosmos DB para um espaço de trabalho do Synapse. O aluno entenderá como habilitar e configurar o link Synapse e em seguida, como consultar o repositório analítico do Azure Cosmos DB usando Apache Spark e SQL sem servidor.

  #### Lições

  *   Projetar processamento analítico e transacional híbrido usando o Azure Synapse Analytics

  * Configurar o Azure Synapse Link com o Azure Cosmos DB

  *   Consultar o Azure Cosmos DB com pools do Apache Spark

  *   Consultar o Azure Cosmos DB com pools SQL sem servidor


  #### Laboratório: Suporte ao Hybrid Transactional Analytical Processing (HTAP) com o Azure Synapse Link

  ####
  * Configurar o Azure Synapse Link com o Azure Cosmos DB
  *   Consultar Azure Cosmos DB com Apache Spark para Synapse Analytics
  *   Consultar o Azure Cosmos DB com pool SQL sem servidor para o Azure Synapse Analytics

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Projetar processamento analítico e transacional híbrido usando o Azure Synapse Analytics

  * Configurar o Azure Synapse Link com o Azure Cosmos DB

  *   Consultar Azure Cosmos DB com Apache Spark para Azure Synapse Analytics

  *   Consultar Azure Cosmos DB com SQL sem servidor para Azure Synapse Analytics


  ### Módulo 10: Processamento de fluxo em tempo real com Stream Analytics

  Neste módulo, os alunos aprenderão como processar dados de streaming com o Azure Stream Analytics. O aluno irá ingerir dados de telemetria do veículo em Event Hubs e em seguida, processar esses dados em tempo real, usando várias funções de janelas no Azure Stream Analytics. Eles enviarão os dados para o Azure Synapse Analytics. Finalmente, o aluno aprenderá como dimensionar o trabalho do Stream Analytics para aumentar o rendimento.

  #### Lições

  *   Ativar mensagens confiáveis para aplicativos de Big Data usando Azure Event Hubs

  *   Trabalhar com fluxos de dados usando o Azure Stream Analytics

  *   Ingerir fluxos de dados com o Azure Stream Analytics


  #### Laboratório: Processamento de fluxo em tempo real com Stream Analytics

  ####
  *   Usar Stream Analytics para processar dados em tempo real de Event Hubs
  *   Usar funções de janela do Stream Analytics para criar agregados e saída para o Synapse Analytics
  *   Dimensionar o trabalho do Azure Stream Analytics para aumentar a taxa de transferência por meio do particionamento
  *   Reparticionar a entrada do stream para otimizar a paralelização

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Ativar mensagens confiáveis para aplicativos de Big Data usando Event Hubs do Azure

  *   Trabalhar com fluxos de dados usando o Azure Stream Analytics

  *   Ingerir fluxos de dados com o Azure Stream Analytics

  ### Módulo 11: Criar uma solução de processamento de fluxo com Event Hubs e Azure Databricks

  Neste módulo, os alunos aprenderão como ingerir e processar dados de streaming em escala com Event Hubs e Spark Structured Streaming no Azure Databricks. O aluno aprenderá os principais recursos e usos do Structured Streaming. O aluno implementará janelas deslizantes para agregar blocos de dados e aplicar marcas d'água para remover dados obsoletos. Por fim, o aluno se conectará a Event Hubs para ler e gravar fluxos.

  #### Lições

  *   Processar dados de streaming com Structured Streaming do Azure Databricks


  #### Laboratório: Criar uma solução de processamento de fluxo com Event Hubs e Azure Databricks

  ####
  *   Explorar os principais recursos e usos de Structured Streaming
  *   Transmitir dados de um arquivo e grave-os em um sistema de arquivos distribuído
  *   Usar janelas deslizantes para agregar dados em vez de todos os dados
  *   Aplicar marca d'água para remover dados obsoletos
  *   Conectar a Event Hubs para ler e gravar streams

  Depois de concluir este módulo, os alunos serão capazes de:

  *   Processar dados de streaming com Azure Databricks structured streaming
